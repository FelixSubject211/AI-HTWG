{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PohCF88YwWgk"
      },
      "source": [
        "# Aufgaben Blatt 4 KI Machine Learning I\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9sieFkrwWgm"
      },
      "source": [
        "## Aufgabe 1 (Lineare Regression)\n",
        "\n",
        "Bearbeiten Sie die Aufgabe https://github.com/oduerr/ki/blob/main/linear_regression/lr_gradient_descent.ipynb\n",
        "\n",
        "Versuchen Sie den Code zu verstehen und machen die kleineren Aufgaben, die in dem notebook besprochen werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr2BSdsNwWgm"
      },
      "source": [
        "## Aufgabe 2 (Titanic)\n",
        "In dieser Aufgabe nehmen Sie an der Titanic Challenge (https://www.kaggle.com/c/titanic) teil. Sie können die Aufgabe am eigenen PC lösen oder direkt in Kaggle lösen. Die Daten liegen auch auf Moodle. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-_0tiX-wWgm"
      },
      "source": [
        "a) Lesen Sie die Trainingsdaten ein und teilen Sie sie in ein Validierungsdatenset (20%) und in ein eigentliches Trainigsdatenset (80%) auf. Finden Sie auf dem Trainigsdatenset eine Regel für das Überleben alleine aufgrund der Klasse des Tickets (Pclass). Wenden Sie diese Regel auf die Validierungsdaten an. Wie gut ist die Genauigkeit (Anteil der korrekten Klassifikationen) auf den Validierungsdaten?  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PGm0-jEawWgn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Hinweise zum Einlesen\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "train_val = pd.read_csv('titanic/train.csv')\n",
        "\n",
        "# Hinweise zum Erzeugen einer Tabelle\n",
        "# pd.crosstab(...)\n",
        "\n",
        "# Hinweise um die Accuracy zu berechnen\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "712\n",
            "179\n",
            "Klasse 1: Überlebende/Tot = 109/170 Verhältnis = 0.6411764705882353\n",
            "Klasse 2: Überlebende/Tot = 68/154 Verhältnis = 0.44155844155844154\n",
            "Klasse 3: Überlebende/Tot = 91/388 Verhältnis = 0.2345360824742268\n",
            "{1: 0.6411764705882353, 2: 0.44155844155844154, 3: 0.2345360824742268}\n",
            "Vorhersagen: 108\n",
            "Genauigkeit: 0.6033519553072626\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training_set, validation_set = train_test_split(train_val, test_size=0.2)\n",
        "print(len(training_set))\n",
        "print(len(validation_set))\n",
        "\n",
        "## wer hat überlebt\n",
        "\n",
        "classes = {\n",
        "    1: (0, 0),\n",
        "    2: (0, 0),\n",
        "    3: (0, 0)\n",
        "}\n",
        "\n",
        "for person in training_set.itertuples(index=False):\n",
        "    key = person[2]\n",
        "    current_tuple = classes[key]\n",
        "    updated_tuple = (current_tuple[0] + 1, current_tuple[1] + person[1])\n",
        "    classes[key] = updated_tuple\n",
        "\n",
        "for key, value in classes.items():\n",
        "    total = value[0]\n",
        "    survived = value[1]\n",
        "    ratio = survived / total if total != 0 else 0\n",
        "    print(f\"Klasse {key}: Überlebende/Tot = {survived}/{total} Verhältnis = {ratio}\")\n",
        "\n",
        "class_survival_rate = {}\n",
        "\n",
        "for key, value in classes.items():\n",
        "    total = value[0]\n",
        "    survived = value[1]\n",
        "    ratio = survived / total if total != 0 else 0\n",
        "    class_survival_rate[key] = ratio\n",
        "\n",
        "print(class_survival_rate)\n",
        "\n",
        "## Vorhersage\n",
        "\n",
        "import random\n",
        "val_predictions = []\n",
        "for passenger in validation_set.itertuples(index=False):\n",
        "    predicted_survival = 1 if random.random() < class_survival_rate[passenger[2]] else 0\n",
        "    val_predictions.append(predicted_survival)\n",
        "\n",
        "correct_predictions = validation_set['Survived'] == val_predictions\n",
        "print(f\"Vorhersagen: {sum(correct_predictions)}\")\n",
        "accuracy = sum(correct_predictions) / len(correct_predictions)\n",
        "print(\"Genauigkeit:\", accuracy)\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "original_test_set = pd.read_csv(\"titanic/test.csv\")\n",
        "\n",
        "val_predictions = []\n",
        "for passenger in original_test_set.itertuples():\n",
        "    predicted_survival = 1 if random.random() < class_survival_rate[passenger[2]] else 0\n",
        "    val_predictions.append(predicted_survival)\n",
        "\n",
        "output = pd.DataFrame({'PassengerId': original_test_set[\"PassengerId\"], 'Survived': val_predictions})\n",
        "output.to_csv('my_submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAb6YDtTwWgn"
      },
      "source": [
        "b) Wenden Sie die Regel aus a) auf die Testdaten an und laden Sie Ihre Lösung hoch. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# 0.56689 war das Ergebnis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0YqDhK3wWgp"
      },
      "source": [
        "c) Logistische Regression mit Pclass\n",
        "\n",
        "Trainieren Sie eine logistische Regression mit den Variablen 'Pclass'. Verwenden Sie die Klasse `sklearn.linear_model.LogisticRegression`. Berechnen Sie die Accuracy auf dem Validierungsset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Genauigkeit: 0.6312849162011173\n",
            "0.6312849162011173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/felixfischer/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "logReg = LogisticRegression()\n",
        "logReg.fit(training_set[[\"Pclass\"]], training_set[[\"Survived\"]])\n",
        "\n",
        "prediction = logReg.predict(validation_set[[\"Pclass\"]])\n",
        "\n",
        "accuracy = accuracy_score(validation_set[[\"Survived\"]], prediction)\n",
        "print(\"Genauigkeit:\", accuracy)\n",
        "\n",
        "print(logReg.score(validation_set[[\"Pclass\"]], validation_set[[\"Survived\"]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-xC04XswWgp"
      },
      "source": [
        "d) Coding / Feature engineering \n",
        "\n",
        "d.i) Missing Values:\n",
        "\n",
        "Verwenden Sie nun weitere Features. Die Variable Age enthält Missing values, die Sie durch folgenden code ersetzen können (was passiert da?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6i9qi9ywwWgq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/lr/n_w7l2nn1klg5pbt8vrzdt7m0000gn/T/ipykernel_87315/765635614.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train_data[\"Age\"].fillna(train_data[\"Age\"].median(skipna=True), inplace=True)\n",
            "/var/folders/lr/n_w7l2nn1klg5pbt8vrzdt7m0000gn/T/ipykernel_87315/765635614.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test_data[\"Age\"].fillna(test_data[\"Age\"].median(skipna=True), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "val[\"Age\"].fillna(train[\"Age\"].median(skipna=True), inplace=True)\n",
        "train[\"Age\"].fillna(train[\"Age\"].median(skipna=True), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxNwZco7wWgq"
      },
      "source": [
        "d.ii) Kategorische Variable\n",
        "\n",
        "Verwenden Sie die Funktion `pd.get_dummies` um die Variablen 'Pclass' and 'Sex' in numerische Werte umzuwandeln. Führen Sie nun eine logistische Regression durch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu8UOcKAwWgq"
      },
      "source": [
        "e) Weitere Klassifikatoren. Neben der logistischen Regression, gibt es weitere Klassifikatoren. Der Random-Forest ist ein recht stabiler Klassifikator, was wäre die Performance von diesem Klassifikator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v0eRJVGSwWgr"
      },
      "outputs": [],
      "source": [
        "# Hinweise zur Lösung\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "#rf hat nun gleiches interface, wie die logistische Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe_oIy11wWgr"
      },
      "source": [
        "f) [optional] Versuchen Sie weitere Features zu erzeugen und laden den besten Klassifikator auf Kaggle hoch. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc49pWuewWgr"
      },
      "source": [
        "## Aufgabe 3 Titanic mit Neuronalen Netzen \n",
        "\n",
        "Hinweis: Diese Aufgabe kann erst nach der dritten Vorlesung in ML gemacht werden.\n",
        "\n",
        "Mit den gleichen Daten, wie in der Aufgabe 2 d. Erstellen Sie ein fully connected neural network und fitten es an die Ttrainingsdaten. Verwenden Sie mindestens zwei hidden Layer. Plotten Sie den Verlauf der Loss Kurve für die Trainings- und Validierungsdaten. Optional: Laden Sie Ihre beste Lösung auf Kaggle hoch. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aYxfamTkwWgr",
        "outputId": "80a28e11-8256-4ab2-97ad-8f1d0ddda78e",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Unrecognized keyword arguments passed to Dense: {'batch_input_shape': (None, 4)}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m----> 8\u001b[0m model\u001b[38;5;241m.\u001b[39madd(\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msigmoid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_input_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#We have 4 input features\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#...\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87\u001b[0m, in \u001b[0;36mDense.__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     74\u001b[0m     units,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     86\u001b[0m ):\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mactivity_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivity_regularizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m activations\u001b[38;5;241m.\u001b[39mget(activation)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/layers/layer.py:264\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m     )\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast \u001b[38;5;241m=\u001b[39m autocast\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Dense: {'batch_input_shape': (None, 4)}"
          ]
        }
      ],
      "source": [
        "#Sie können von folgendem Code starten um das Netzwerk zu definieren, füllen Sie die ...\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(..., activation='sigmoid', batch_input_shape=(None, 4))) #We have 4 input features\n",
        "#...\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9M8BQdo5wWgs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "ki_ml_blatt_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
